{"paragraphs":[{"title":"Getting Started with Spark - Spark Workshop, Code4Lib 2018","text":"%md\nSpark Workshop, code4lib 2018\nMaterials at [github.com/spark4lib/code4lib2018](https://github.com/spark4lib/code4lib2018)\n\nThe following steps should also be available, with other notes, here: [https://github.com/spark4lib/code4lib2018/tree/master/worksheets/](https://github.com/spark4lib/code4lib2018/tree/master/worksheets) .","dateUpdated":"2018-02-11T18:27:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Spark Workshop, code4lib 2018<br/>Materials at <a href=\"https://github.com/spark4lib/code4lib2018\">github.com/spark4lib/code4lib2018</a></p>\n<p>The following steps should also be available, with other notes, here: <a href=\"https://github.com/spark4lib/code4lib2018/tree/master/worksheets\">https://github.com/spark4lib/code4lib2018/tree/master/worksheets/</a> .</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518373679851_1776327955","id":"20180131-144721_1911570621","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4222"},{"title":"Introduction","text":"%md\nIn this session, you will learn Zeppelin, Spark, & Spark SQL basics via primarily the DataFrames API. We are starting with a really simple dataset to focus on the tools. In the next session, we will use an expanded cultural heritage metadata set.\n\n#### Datasets? DataFrames?\n\nA **Dataset** is a distributed collection of data. Dataset provides the benefits of strong typing, ability to use powerful lambda functions with the benefits of (Spark SQL’s) optimized execution engine. A Dataset can be constructed from JVM objects and then manipulated using functional transformations (map, flatMap, filter, etc.). The Dataset API is available in Scala and Java.\n\nA **DataFrame** is a Dataset organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood. DataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing RDDs. The DataFrame API is available in Scala, Java, Python, and R. In Scala and Java, a DataFrame is represented by a Dataset of Rows. In the Scala API, DataFrame is simply a type alias of Dataset[Row]. (Note that in Scala type parameters (generics) are enclosed in square brackets.)\n\n[[source](http://spark.apache.org/docs/2.0.0/sql-programming-guide.html#datasets-and-dataframes)]\n\n#### How to run a paragraph\n\nTo run a paragraph in a Zeppelin notebook, you can either click the `play` button (blue triangle) on the right-hand side or click on the paragraph simply press `Shift + Enter`.\n\n#### What are Zeppelin Interpreters?\n\nIn the following paragraphs we are going to execute Spark code, run shell commands to download and move files, run sql queries etc. Each paragraph will start with `%` followed by an interpreter name, e.g. `%spark2` for a Spark 2.x interpreter. Different interpreter names indicate what will be executed: code, markdown, html etc.  This allows you to perform data ingestion, munging, wrangling, visualization, analysis, processing and more, all in one place!\n\nThroughout this notebook we will use the following interpreters:\n\n- `` - the default interpreter is set to be PySpark for our Workshop Docker Container.\n- `%spark` - Spark interpreter to run Spark code written in Scala\n- `%spark.sql` - Spark SQL interprter (to execute SQL queries against temporary tables in Spark)\n- `%sh` - Shell interpreter to run shell commands\n- `%angular` - Angular interpreter to run Angular and HTML code\n- `%md` - Markdown for displaying formatted text, links, and images\n\nTo learn more about Zeppelin interpreters check out this [link](https://zeppelin.apache.org/docs/0.5.6-incubating/manual/interpreters.html).","dateUpdated":"2018-02-11T18:27:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":true,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In this session, you will learn Zeppelin, Spark, &amp; Spark SQL basics via primarily the DataFrames API. We are starting with a really simple dataset to focus on the tools. In the next session, we will use an expanded cultural heritage metadata set.</p>\n<h4>Datasets? DataFrames?</h4>\n<p>A <strong>Dataset</strong> is a distributed collection of data. Dataset provides the benefits of strong typing, ability to use powerful lambda functions with the benefits of (Spark SQL’s) optimized execution engine. A Dataset can be constructed from JVM objects and then manipulated using functional transformations (map, flatMap, filter, etc.). The Dataset API is available in Scala and Java.</p>\n<p>A <strong>DataFrame</strong> is a Dataset organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood. DataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing RDDs. The DataFrame API is available in Scala, Java, Python, and R. In Scala and Java, a DataFrame is represented by a Dataset of Rows. In the Scala API, DataFrame is simply a type alias of Dataset[Row]. (Note that in Scala type parameters (generics) are enclosed in square brackets.)</p>\n<p>[<a href=\"http://spark.apache.org/docs/2.0.0/sql-programming-guide.html#datasets-and-dataframes\">source</a>]</p>\n<h4>How to run a paragraph</h4>\n<p>To run a paragraph in a Zeppelin notebook, you can either click the <code>play</code> button (blue triangle) on the right-hand side or click on the paragraph simply press <code>Shift + Enter</code>.</p>\n<h4>What are Zeppelin Interpreters?</h4>\n<p>In the following paragraphs we are going to execute Spark code, run shell commands to download and move files, run sql queries etc. Each paragraph will start with <code>%</code> followed by an interpreter name, e.g. <code>%spark2</code> for a Spark 2.x interpreter. Different interpreter names indicate what will be executed: code, markdown, html etc. This allows you to perform data ingestion, munging, wrangling, visualization, analysis, processing and more, all in one place!</p>\n<p>Throughout this notebook we will use the following interpreters:</p>\n<ul>\n  <li>`` - the default interpreter is set to be PySpark for our Workshop Docker Container.</li>\n  <li><code>%spark</code> - Spark interpreter to run Spark code written in Scala</li>\n  <li><code>%spark.sql</code> - Spark SQL interprter (to execute SQL queries against temporary tables in Spark)</li>\n  <li><code>%sh</code> - Shell interpreter to run shell commands</li>\n  <li><code>%angular</code> - Angular interpreter to run Angular and HTML code</li>\n  <li><code>%md</code> - Markdown for displaying formatted text, links, and images</li>\n</ul>\n<p>To learn more about Zeppelin interpreters check out this <a href=\"https://zeppelin.apache.org/docs/0.5.6-incubating/manual/interpreters.html\">link</a>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518373679864_1782099188","id":"20180211-041642_2058564180","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4223"},{"title":"Environment Set-up Test","text":"%spark\n\nprintln(\"Spark Version: \" + sc.version)\n\nval penndata = sc.textFile(\"penn.csv\")\nval cmoadata = sc.textFile(\"cmoa.csv\")\nprintln(\"penn count: \" + penndata.count)\nprintln(\"cmoadata count: \" + cmoadata.count)","dateUpdated":"2018-02-11T18:27:59+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Spark Version: 2.1.0\npenndata: org.apache.spark.rdd.RDD[String] = penn.csv MapPartitionsRDD[2538] at textFile at <console>:28\ncmoadata: org.apache.spark.rdd.RDD[String] = cmoa.csv MapPartitionsRDD[2540] at textFile at <console>:27\npenn count: 379317\ncmoadata count: 34596\n"}]},"apps":[],"jobName":"paragraph_1518373679865_1781714439","id":"20180131-144538_432654498","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4224"},{"title":"Preview Sample Data","text":"%sh\ncat code4lib2018/sample-data/small-sample.csv","dateUpdated":"2018-02-11T20:38:12+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Name,Institution Type,Format,URL,Description,Informal Score\r\nCMOA,Museum,\"JSON, CSV\",https://github.com/cmoa/collection,,10\r\nPenn Museum,Museum,\"JSON, CSV, XML\",https://www.penn.museum/collections/data.php,JSON is poorly structured,7\r\nMet Museum,Museum,CSV,,\"¯\\_(ツ)_/¯\r\n\",3\r\nDigitalNZ Te Puna Web Directory,Library,XML,https://natlib.govt.nz/files/data/tepunawebdirectory.xml,MARC XML,3\r\nCanadian Subject Headings,Library,RDF/XML,http://www.collectionscanada.gc.ca/obj/900/f11/040004/csh.rdf,\"Ugh, rdf\",4\r\nDPLA,Aggregator ,\"CSV,JSON,XML\",dp.la,,100\r\n"}]},"apps":[],"jobName":"paragraph_1518373679865_1781714439","id":"20180210-010216_1168213332","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4225","user":"anonymous","dateFinished":"2018-02-11T20:38:12+0000","dateStarted":"2018-02-11T20:38:12+0000"},{"title":"Our Sample Data","text":"%md\n\nName | Institution Type | Format | URL | Description | Informal Score\n---- | ---------------- | ------ | --- | ----------- | --------------\nCMOA | Museum | \"JSON, CSV\" | https://github.com/cmoa/collection |  | 10\nPenn Museum | Museum | \"JSON, CSV, XML\" | https://www.penn.museum/collections/data.php | JSON is poorly structured | 7\nMet Museum | Museum | CSV |  | \"¯\\_(ツ)_/¯\n\" | 3\nDigitalNZ Te Puna Web Directory | Library | XML | https://natlib.govt.nz/files/data/tepunawebdirectory.xml | MARC XML | 3\nCanadian Subject Headings | Library | RDF/XML | http://www.collectionscanada.gc.ca/obj/900/f11/040004/csh.rdf | \"Ugh, rdf\" | 4\nDPLA | Aggregator  | \"CSV,JSON,XML\" | dp.la | | 100\n","dateUpdated":"2018-02-11T18:27:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<table>\n  <thead>\n    <tr>\n      <th>Name </th>\n      <th>Institution Type </th>\n      <th>Format </th>\n      <th>URL </th>\n      <th>Description </th>\n      <th>Informal Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>CMOA </td>\n      <td>Museum </td>\n      <td>&ldquo;JSON, CSV&rdquo; </td>\n      <td><a href=\"https://github.com/cmoa/collection\">https://github.com/cmoa/collection</a> </td>\n      <td> </td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>Penn Museum </td>\n      <td>Museum </td>\n      <td>&ldquo;JSON, CSV, XML&rdquo; </td>\n      <td><a href=\"https://www.penn.museum/collections/data.php\">https://www.penn.museum/collections/data.php</a> </td>\n      <td>JSON is poorly structured </td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <td>Met Museum </td>\n      <td>Museum </td>\n      <td>CSV </td>\n      <td> </td>\n      <td>&ldquo;¯_(ツ)_/¯<br/>&rdquo; </td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>DigitalNZ Te Puna Web Directory </td>\n      <td>Library </td>\n      <td>XML </td>\n      <td><a href=\"https://natlib.govt.nz/files/data/tepunawebdirectory.xml\">https://natlib.govt.nz/files/data/tepunawebdirectory.xml</a> </td>\n      <td>MARC XML </td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>Canadian Subject Headings </td>\n      <td>Library </td>\n      <td>RDF/XML </td>\n      <td><a href=\"http://www.collectionscanada.gc.ca/obj/900/f11/040004/csh.rdf\">http://www.collectionscanada.gc.ca/obj/900/f11/040004/csh.rdf</a> </td>\n      <td>&ldquo;Ugh, rdf&rdquo; </td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>DPLA </td>\n      <td>Aggregator </td>\n      <td>&ldquo;CSV,JSON,XML&rdquo; </td>\n      <td>dp.la </td>\n      <td> </td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}]},"apps":[],"jobName":"paragraph_1518373679866_1782868686","id":"20180211-043610_1714070353","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4226"},{"title":"","text":"%md\n# Part 1: Creating a Dataframe Instance from CSV","dateUpdated":"2018-02-11T18:27:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Part 1: Creating a Dataframe Instance from CSV</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1518373679866_1782868686","id":"20180211-043612_1888524633","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4227"},{"title":"Read a CSV File into a Dataframe Instance & View It","text":"spark.read.csv(\"small-sample.csv\")\nspark.read.csv(\"small-sample.csv\").show()","dateUpdated":"2018-02-11T18:27:59+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                 _c0|             _c1|           _c2|                 _c3|                 _c4|           _c5|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                Name|Institution Type|        Format|                 URL|         Description|Informal Score|\n|                CMOA|          Museum|     JSON, CSV|https://github.co...|                null|            10|\n|         Penn Museum|          Museum|JSON, CSV, XML|https://www.penn....|JSON is poorly st...|             7|\n|          Met Museum|          Museum|           CSV|                null|            ¯_(ツ)_/¯|          null|\n|                  ,3|            null|          null|                null|                null|          null|\n|DigitalNZ Te Puna...|         Library|           XML|https://natlib.go...|            MARC XML|             3|\n|Canadian Subject ...|         Library|       RDF/XML|http://www.collec...|            Ugh, rdf|             4|\n|                DPLA|     Aggregator |  CSV,JSON,XML|               dp.la|                null|           100|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679866_1782868686","id":"20180205-215000_1411168291","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4228"},{"title":"Read a CSV File into a Dataframe Instance with Headers","text":"spark.read.csv(\"code4lib2018/sample-data/small-sample.csv\", header=True).show()","dateUpdated":"2018-02-11T20:38:30+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                Name|Institution Type|        Format|                 URL|         Description|Informal Score|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                CMOA|          Museum|     JSON, CSV|https://github.co...|                null|            10|\n|         Penn Museum|          Museum|JSON, CSV, XML|https://www.penn....|JSON is poorly st...|             7|\n|          Met Museum|          Museum|           CSV|                null|            ¯_(ツ)_/¯|          null|\n|                  ,3|            null|          null|                null|                null|          null|\n|DigitalNZ Te Puna...|         Library|           XML|https://natlib.go...|            MARC XML|             3|\n|Canadian Subject ...|         Library|       RDF/XML|http://www.collec...|            Ugh, rdf|             4|\n|                DPLA|     Aggregator |  CSV,JSON,XML|               dp.la|                null|           100|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679867_1782483937","id":"20180210-002750_1470779955","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4229","user":"anonymous","dateFinished":"2018-02-11T20:38:33+0000","dateStarted":"2018-02-11T20:38:30+0000"},{"title":"Read a CSV File into a Dataframe Instance with DROPMALFORMED mode","text":"spark.read.csv(\"code4lib2018/sample-data/small-sample.csv\", header=True, mode=\"DROPMALFORMED\").show()","dateUpdated":"2018-02-11T20:38:48+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                Name|Institution Type|        Format|                 URL|         Description|Informal Score|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                CMOA|          Museum|     JSON, CSV|https://github.co...|                null|            10|\n|         Penn Museum|          Museum|JSON, CSV, XML|https://www.penn....|JSON is poorly st...|             7|\n|DigitalNZ Te Puna...|         Library|           XML|https://natlib.go...|            MARC XML|             3|\n|Canadian Subject ...|         Library|       RDF/XML|http://www.collec...|            Ugh, rdf|             4|\n|                DPLA|     Aggregator |  CSV,JSON,XML|               dp.la|                null|           100|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679867_1782483937","id":"20180210-002834_476482959","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4230","user":"anonymous","dateFinished":"2018-02-11T20:38:48+0000","dateStarted":"2018-02-11T20:38:48+0000"},{"title":"Read a CSV File into a Dataframe Instance with multiLine...?","text":"spark.read.csv(\"code4lib2018/sample-data/small-sample.csv\", header=True, multiLine=True).show()","dateUpdated":"2018-02-11T20:38:59+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-6267687467104686214.py\", line 367, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-6267687467104686214.py\", line 360, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 1, in <module>\nTypeError: csv() got an unexpected keyword argument 'multiLine'\n\n"}]},"apps":[],"jobName":"paragraph_1518373679869_1780175444","id":"20180210-002956_613592773","dateCreated":"2018-02-11T18:27:59+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:4231","user":"anonymous","dateFinished":"2018-02-11T20:38:59+0000","dateStarted":"2018-02-11T20:38:59+0000"},{"title":"Temporary Python Repair of CSV Newlines within PySpark","text":"import csv\n\n# we will see a cleaner way using pyspark to handle this issue later\n# though really, use proper quoting with Spark 2.2.x & multifile=True\n\nwith open('code4lib2018/sample-data/small-sample.csv') as fh:\n    test = csv.reader(fh)\n    with open('code4lib2018/sample-data/small-sample-stripped.csv', 'w') as fout:\n        test_write = csv.writer(fout, quoting=csv.QUOTE_ALL)\n        for row in test:\n            new_row = [val.replace(\"\\r\\n\", \"\") for val in row]\n            test_write.writerow(new_row)","dateUpdated":"2018-02-11T20:39:22+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518373679870_1781329691","id":"20180210-004851_951565379","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4232","user":"anonymous","dateFinished":"2018-02-11T20:39:22+0000","dateStarted":"2018-02-11T20:39:22+0000"},{"title":"Check that Our Temporary Repair Worked for our CSV","text":"%sh\ncat 'code4lib2018/sample-data/small-sample-stripped.csv'","dateUpdated":"2018-02-11T20:39:41+0000","config":{"lineNumbers":true,"editorSetting":{"language":"sh","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sh","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Name,Institution Type,Format,URL,Description,Informal Score\r\nCMOA,Museum,\"JSON, CSV\",https://github.com/cmoa/collection,,10\r\nPenn Museum,Museum,\"JSON, CSV, XML\",https://www.penn.museum/collections/data.php,JSON is poorly structured,7\r\nMet Museum,Museum,CSV,,\"¯\\_(ツ)_/¯\r\n\",3\r\nDigitalNZ Te Puna Web Directory,Library,XML,https://natlib.govt.nz/files/data/tepunawebdirectory.xml,MARC XML,3\r\nCanadian Subject Headings,Library,RDF/XML,http://www.collectionscanada.gc.ca/obj/900/f11/040004/csh.rdf,\"Ugh, rdf\",4\r\nDPLA,Aggregator ,\"CSV,JSON,XML\",dp.la,,100\r\n"}]},"apps":[],"jobName":"paragraph_1518373679873_1864820202","id":"20180210-004958_2013545188","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4233","user":"anonymous","dateFinished":"2018-02-11T20:39:28+0000","dateStarted":"2018-02-11T20:39:28+0000"},{"title":"Revisit our CSV as a Dataframe & It's Inferred Schema","text":"spark.read.csv(\"code4lib2018/sample-data/small-sample-stripped.csv\", header=True, inferSchema=True).printSchema()","dateUpdated":"2018-02-11T20:39:44+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- Name: string (nullable = true)\n |-- Institution Type: string (nullable = true)\n |-- Format: string (nullable = true)\n |-- URL: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Informal Score: integer (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1518373679873_1864820202","id":"20180210-005045_657129235","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4234","user":"anonymous","dateFinished":"2018-02-11T20:39:44+0000","dateStarted":"2018-02-11T20:39:44+0000"},{"title":"Create Our Own Schema & Read the CSV into a Dataframe Instance with our Schema","text":"from pyspark.sql.types import *\n\ncustomSchema = StructType([\n  StructField(\"Name\", StringType(), True),\n  StructField(\"Institution Type\", StringType(), True),\n  StructField(\"Format\", StringType(), True),\n  StructField(\"URL\", StringType(), True),\n  StructField(\"Description\", StringType(), True),\n  StructField(\"Informal Score\", DecimalType(), True)])\n\nsampleDf = spark.read.csv(\"code4lib2018/sample-data/small-sample-stripped.csv\", header=True, schema=customSchema)\nsampleDf.show()","dateUpdated":"2018-02-11T20:39:55+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                Name|Institution Type|        Format|                 URL|         Description|Informal Score|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                CMOA|          Museum|     JSON, CSV|https://github.co...|                null|            10|\n|         Penn Museum|          Museum|JSON, CSV, XML|https://www.penn....|JSON is poorly st...|             7|\n|          Met Museum|          Museum|           CSV|                null|            ¯_(ツ)_/¯|             3|\n|DigitalNZ Te Puna...|         Library|           XML|https://natlib.go...|            MARC XML|             3|\n|Canadian Subject ...|         Library|       RDF/XML|http://www.collec...|            Ugh, rdf|             4|\n|                DPLA|     Aggregator |  CSV,JSON,XML|               dp.la|                null|           100|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679874_1865974449","id":"20180205-224139_1405421836","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4235","user":"anonymous","dateFinished":"2018-02-11T20:39:55+0000","dateStarted":"2018-02-11T20:39:55+0000"},{"text":"%md\n### Stopping Point: Have you been able to walk through and load your CSV?","user":"anonymous","dateUpdated":"2018-02-11T20:41:24+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518381640539_1976533582","id":"20180211-204040_1741647870","dateCreated":"2018-02-11T20:40:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8550","dateFinished":"2018-02-11T20:41:13+0000","dateStarted":"2018-02-11T20:41:13+0000","title":"","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Stopping Point: Have you been able to walk through and load your CSV?</h3>\n</div>"}]}},{"title":"","text":"%md\n# Part 2: Simple Analysis of our Dataset via Dataframe API","dateUpdated":"2018-02-11T18:27:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Part 2: Simple Analysis of our Dataset via Dataframe API</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1518373679874_1865974449","id":"20180211-044238_542100528","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4236"},{"title":"Return First n Rows in your Dataframe ( .head(n) )","text":"sampleDf.head(2)","dateUpdated":"2018-02-11T20:40:01+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[Row(Name=u'CMOA', Institution Type=u'Museum', Format=u'JSON, CSV', URL=u'https://github.com/cmoa/collection', Description=None, Informal Score=Decimal('10')), Row(Name=u'Penn Museum', Institution Type=u'Museum', Format=u'JSON, CSV, XML', URL=u'https://www.penn.museum/collections/data.php', Description=u'JSON is poorly structured', Informal Score=Decimal('7'))]\n"}]},"apps":[],"jobName":"paragraph_1518373679888_1871360933","id":"20180210-203445_1454325544","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4238","focus":true,"user":"anonymous","dateFinished":"2018-02-11T20:40:01+0000","dateStarted":"2018-02-11T20:40:01+0000"},{"title":"Show Columns ( .columns() ) & Number of Columns ( .len() ) in your Dataframe","text":"print(sampleDf.columns)\nprint(len(sampleDf.columns))","dateUpdated":"2018-02-11T20:41:45+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['Name', 'Institution Type', 'Format', 'URL', 'Description', 'Informal Score']\n6\n"}]},"apps":[],"jobName":"paragraph_1518373679889_1870976184","id":"20180210-203724_1788119369","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4243","focus":true,"user":"anonymous","dateFinished":"2018-02-11T20:40:04+0000","dateStarted":"2018-02-11T20:40:04+0000"},{"title":"Show Specific Columns ( .select() )","text":"sampleDf.select(\"Name\").show()\nsampleDf.select(\"Name\", \"Informal Score\").show()","dateUpdated":"2018-02-11T20:41:59+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":6,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+\n|                Name|\n+--------------------+\n|                CMOA|\n|         Penn Museum|\n|          Met Museum|\n|DigitalNZ Te Puna...|\n|Canadian Subject ...|\n|                DPLA|\n+--------------------+\n\n+--------------------+--------------+\n|                Name|Informal Score|\n+--------------------+--------------+\n|                CMOA|            10|\n|         Penn Museum|             7|\n|          Met Museum|             3|\n|DigitalNZ Te Puna...|             3|\n|Canadian Subject ...|             4|\n|                DPLA|           100|\n+--------------------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679889_1870976184","id":"20180211-044743_1705262796","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4244","focus":true,"user":"anonymous","dateFinished":"2018-02-11T20:40:07+0000","dateStarted":"2018-02-11T20:40:07+0000"},{"title":"Selecting Columns ( .select() ) versus Apply Filters ( .filter() )","text":"scoresBooleanDf = sampleDf.select('Name', 'URL', sampleDf['Informal Score'] > 5)\nscoresBooleanDf.show()\n\nhighScoresDf = sampleDf.filter(sampleDf['Informal Score'] > 5)\nhighScoresDf.select('Name', 'URL', 'Informal Score').show()","dateUpdated":"2018-02-11T20:42:03+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":6,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+--------------------+\n|                Name|                 URL|(Informal Score > 5)|\n+--------------------+--------------------+--------------------+\n|                CMOA|https://github.co...|                true|\n|         Penn Museum|https://www.penn....|                true|\n|          Met Museum|                null|               false|\n|DigitalNZ Te Puna...|https://natlib.go...|               false|\n|Canadian Subject ...|http://www.collec...|               false|\n|                DPLA|               dp.la|                true|\n+--------------------+--------------------+--------------------+\n\n+-----------+--------------------+--------------+\n|       Name|                 URL|Informal Score|\n+-----------+--------------------+--------------+\n|       CMOA|https://github.co...|            10|\n|Penn Museum|https://www.penn....|             7|\n|       DPLA|               dp.la|           100|\n+-----------+--------------------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679889_1870976184","id":"20180210-011244_1927422767","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4245","focus":true,"user":"anonymous","dateFinished":"2018-02-11T20:40:18+0000","dateStarted":"2018-02-11T20:40:17+0000"},{"title":"How Many Rows? ( .count() )","text":"numSampleDf = sampleDf.count()\nnumHighScoresDf = highScoresDf.count()\n\nprint(\"Percentage of Datasets with a Score at or above 5: \" + str(float(numHighScoresDf)/float(numSampleDf)*100) + \"%\")","dateUpdated":"2018-02-11T20:42:30+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Percentage of Datasets with a Score at or above 5: 50.0%\n"}]},"apps":[],"jobName":"paragraph_1518373679875_1865589700","id":"20180205-225126_643532571","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4237","user":"anonymous","dateFinished":"2018-02-11T20:42:30+0000","dateStarted":"2018-02-11T20:42:30+0000","focus":true},{"title":"Show First n Rows of Dataframe in Show View ( .show(n) )","text":"sampleDf.show(2,truncate=True)","dateUpdated":"2018-02-11T20:42:31+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+----------------+--------------+--------------------+--------------------+--------------+\n|       Name|Institution Type|        Format|                 URL|         Description|Informal Score|\n+-----------+----------------+--------------+--------------------+--------------------+--------------+\n|       CMOA|          Museum|     JSON, CSV|https://github.co...|                null|            10|\n|Penn Museum|          Museum|JSON, CSV, XML|https://www.penn....|JSON is poorly st...|             7|\n+-----------+----------------+--------------+--------------------+--------------------+--------------+\nonly showing top 2 rows\n\n"}]},"apps":[],"jobName":"paragraph_1518373679888_1871360933","id":"20180210-203520_832539356","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4239","user":"anonymous","dateFinished":"2018-02-11T20:42:32+0000","dateStarted":"2018-02-11T20:42:31+0000"},{"title":"Show Stats Summary of your Dataframe ( .describe() )","text":"sampleDf.describe().show()","dateUpdated":"2018-02-11T20:42:34+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+-----------+----------------+------+--------------------+--------------------+-----------------+\n|summary|       Name|Institution Type|Format|                 URL|         Description|   Informal Score|\n+-------+-----------+----------------+------+--------------------+--------------------+-----------------+\n|  count|          6|               6|     6|                   5|                   4|                6|\n|   mean|       null|            null|  null|                null|                null|          21.1667|\n| stddev|       null|            null|  null|                null|                null|38.71649088782022|\n|    min|       CMOA|     Aggregator |   CSV|               dp.la|JSON is poorly st...|                3|\n|    max|Penn Museum|          Museum|   XML|https://www.penn....|            ¯_(ツ)_/¯|              100|\n+-------+-----------+----------------+------+--------------------+--------------------+-----------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679888_1871360933","id":"20180210-203742_684138715","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4240","user":"anonymous","dateFinished":"2018-02-11T20:42:35+0000","dateStarted":"2018-02-11T20:42:34+0000"},{"title":"Show Stats Summary of a Specific Column ( .describe(colName) , DecimalType)","text":"sampleDf.describe('Informal Score').show()","dateUpdated":"2018-02-11T20:42:59+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":6,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+-----------------+\n|summary|   Informal Score|\n+-------+-----------------+\n|  count|                6|\n|   mean|          21.1667|\n| stddev|38.71649088782022|\n|    min|                3|\n|    max|              100|\n+-------+-----------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679888_1871360933","id":"20180210-211801_243937278","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4241","user":"anonymous","dateFinished":"2018-02-11T20:42:38+0000","dateStarted":"2018-02-11T20:42:38+0000"},{"title":"Show Stats Summary of a Specific Column ( .describe(colName) , StringType)","text":"sampleDf.describe('URL').show()","dateUpdated":"2018-02-11T20:43:04+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":6,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+--------------------+\n|summary|                 URL|\n+-------+--------------------+\n|  count|                   5|\n|   mean|                null|\n| stddev|                null|\n|    min|               dp.la|\n|    max|https://www.penn....|\n+-------+--------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679889_1870976184","id":"20180211-073524_2028466772","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4242","user":"anonymous","dateFinished":"2018-02-11T20:42:41+0000","dateStarted":"2018-02-11T20:42:41+0000"},{"text":"%md\n### Stopping Point: Have you been able to walk through reviewing some Rows & Columns?","user":"anonymous","dateUpdated":"2018-02-11T20:44:05+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518381830265_186341278","id":"20180211-204350_627919107","dateCreated":"2018-02-11T20:43:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9198","dateFinished":"2018-02-11T20:44:06+0000","dateStarted":"2018-02-11T20:44:05+0000","title":"","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Stopping Point: Have you been able to walk through reviewing some Rows &amp; Columns?</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","lineNumbers":true,"title":true,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518381970066_113070421","id":"20180211-204610_53073346","dateCreated":"2018-02-11T20:46:10+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9440","text":"\n","dateUpdated":"2018-02-11T20:46:33+0000","title":"Your Working Space: Analysis of Data I"},{"title":"Order Dataframe Views by a Column ( .orderBy(colName) | .orderBy(colName).desc() )","text":"sampleDf.orderBy(\"Informal Score\").show()\nsampleDf.orderBy(sampleDf[\"Informal Score\"].desc()).show()","dateUpdated":"2018-02-11T20:43:10+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                Name|Institution Type|        Format|                 URL|         Description|Informal Score|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|DigitalNZ Te Puna...|         Library|           XML|https://natlib.go...|            MARC XML|             3|\n|          Met Museum|          Museum|           CSV|                null|            ¯_(ツ)_/¯|             3|\n|Canadian Subject ...|         Library|       RDF/XML|http://www.collec...|            Ugh, rdf|             4|\n|         Penn Museum|          Museum|JSON, CSV, XML|https://www.penn....|JSON is poorly st...|             7|\n|                CMOA|          Museum|     JSON, CSV|https://github.co...|                null|            10|\n|                DPLA|     Aggregator |  CSV,JSON,XML|               dp.la|                null|           100|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                Name|Institution Type|        Format|                 URL|         Description|Informal Score|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n|                DPLA|     Aggregator |  CSV,JSON,XML|               dp.la|                null|           100|\n|                CMOA|          Museum|     JSON, CSV|https://github.co...|                null|            10|\n|         Penn Museum|          Museum|JSON, CSV, XML|https://www.penn....|JSON is poorly st...|             7|\n|Canadian Subject ...|         Library|       RDF/XML|http://www.collec...|            Ugh, rdf|             4|\n|          Met Museum|          Museum|           CSV|                null|            ¯_(ツ)_/¯|             3|\n|DigitalNZ Te Puna...|         Library|           XML|https://natlib.go...|            MARC XML|             3|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679890_1872130431","id":"20180210-212920_1413184855","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4246","user":"anonymous","dateFinished":"2018-02-11T20:43:11+0000","dateStarted":"2018-02-11T20:43:10+0000"},{"title":"Group Values by a Column ( .groupBy(colName) ) ","text":"URLGroupDf = sampleDf.groupBy(\"Format\").count()\n\nURLGroupDf.show()\nURLGroupDf.printSchema()","dateUpdated":"2018-02-11T20:43:15+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":6,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+-----+\n|        Format|count|\n+--------------+-----+\n|           CSV|    1|\n|           XML|    1|\n|     JSON, CSV|    1|\n|JSON, CSV, XML|    1|\n|       RDF/XML|    1|\n|  CSV,JSON,XML|    1|\n+--------------+-----+\n\nroot\n |-- Format: string (nullable = true)\n |-- count: long (nullable = false)\n\n"}]},"apps":[],"jobName":"paragraph_1518373679890_1872130431","id":"20180210-011435_1074589917","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4247","user":"anonymous","dateFinished":"2018-02-11T20:43:17+0000","dateStarted":"2018-02-11T20:43:15+0000"},{"title":"Group Values by a Column then Compute an Aggregation ( .agg(expr) )","text":"# Note, this is setting us up for Splitting Values later on\n\nformatGroupDf = sampleDf.groupBy(\"Format\").agg({\"Informal Score\": 'mean'})\nformatGroupDf.show()\nformatGroupDf.printSchema()","dateUpdated":"2018-02-11T20:43:18+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":6,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+-------------------+\n|        Format|avg(Informal Score)|\n+--------------+-------------------+\n|           CSV|             3.0000|\n|           XML|             3.0000|\n|     JSON, CSV|            10.0000|\n|JSON, CSV, XML|             7.0000|\n|       RDF/XML|             4.0000|\n|  CSV,JSON,XML|           100.0000|\n+--------------+-------------------+\n\nroot\n |-- Format: string (nullable = true)\n |-- avg(Informal Score): decimal(14,4) (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1518373679890_1872130431","id":"20180211-053908_436020978","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4248","user":"anonymous","dateFinished":"2018-02-11T20:43:20+0000","dateStarted":"2018-02-11T20:43:18+0000"},{"title":"Show & Count Distinct Values in a Selected Column ( .distinct() )","text":"# Note, this is also setting us up for Splitting Values later on\n\ndistinctFormatDf = sampleDf.select(\"Format\").distinct()\ndistinctFormatDf.show()\ndistinctFormatDf.count()","dateUpdated":"2018-02-11T20:43:23+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+\n|        Format|\n+--------------+\n|           CSV|\n|           XML|\n|     JSON, CSV|\n|JSON, CSV, XML|\n|       RDF/XML|\n|  CSV,JSON,XML|\n+--------------+\n\n6\n"}]},"apps":[],"jobName":"paragraph_1518373679890_1872130431","id":"20180210-211959_911280658","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4249","user":"anonymous","dateFinished":"2018-02-11T20:43:25+0000","dateStarted":"2018-02-11T20:43:23+0000"},{"title":"Use Aggregations ( .agg() ) & Sql Functions for Number of Distinct Values in Format ( countDistinct(colName) )","text":"from pyspark.sql.functions import countDistinct\n\ncountDistinctDF = sampleDf.select(\"Name\", \"Institution Type\", \"Format\").groupBy(\"Institution Type\").agg(countDistinct(\"Format\"))\ncountDistinctDF.show()","dateUpdated":"2018-02-11T20:49:00+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------+----------------------+\n|Institution Type|count(DISTINCT Format)|\n+----------------+----------------------+\n|         Library|                     2|\n|     Aggregator |                     1|\n|          Museum|                     3|\n+----------------+----------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679891_1871745682","id":"20180211-035942_1079861047","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4250","user":"anonymous","dateFinished":"2018-02-11T20:49:01+0000","dateStarted":"2018-02-11T20:49:00+0000"},{"text":"%md\n### Stopping Point: Have you been able to group, order, get distinct values by column(s)?","user":"anonymous","dateUpdated":"2018-02-11T20:45:23+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518381872295_1282936940","id":"20180211-204432_1327378340","dateCreated":"2018-02-11T20:44:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9285","dateFinished":"2018-02-11T20:45:23+0000","dateStarted":"2018-02-11T20:45:23+0000","title":"","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Stopping Point: Have you been able to group, order, get distinct values by column(s)?</h3>\n</div>"}]}},{"text":"\n","user":"anonymous","dateUpdated":"2018-02-11T20:47:55+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","lineNumbers":true,"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518381942663_209026139","id":"20180211-204542_862151313","dateCreated":"2018-02-11T20:45:42+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9378","title":"Your Working Space: Analysis of Data II"},{"title":"","text":"%md\n# Part 3: Creating New Dataframes to Expand or Rework our Original Dataset","dateUpdated":"2018-02-11T18:27:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Part 3: Creating New Dataframes to Expand or Rework our Original Dataset</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1518373679891_1871745682","id":"20180211-052933_847596982","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4251"},{"title":"Create a Dataframe of DeDuplicated Values ( .dropDuplicates() )","text":"scoresDf = sampleDf.select('Informal Score').dropDuplicates()\nscoresDf.show()","dateUpdated":"2018-02-11T20:48:53+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+\n|Informal Score|\n+--------------+\n|             7|\n|            10|\n|           100|\n|             3|\n|             4|\n+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679891_1871745682","id":"20180210-212128_106635954","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4252","user":"anonymous","dateFinished":"2018-02-11T20:48:54+0000","dateStarted":"2018-02-11T20:48:53+0000"},{"title":"Create a Dataframe with Null Values Dropped ( .dropna() ) or Null Values Filled ( .fillna(fillerVal) )","text":"noNullDf = sampleDf.select('Name', 'URL').dropna()\nnoNullDf.show()\n\nnonNullDf = sampleDf.select('Name', 'URL').fillna('No URL')\nnonNullDf.show()","dateUpdated":"2018-02-11T20:49:08+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+\n|                Name|                 URL|\n+--------------------+--------------------+\n|                CMOA|https://github.co...|\n|         Penn Museum|https://www.penn....|\n|DigitalNZ Te Puna...|https://natlib.go...|\n|Canadian Subject ...|http://www.collec...|\n|                DPLA|               dp.la|\n+--------------------+--------------------+\n\n+--------------------+--------------------+\n|                Name|                 URL|\n+--------------------+--------------------+\n|                CMOA|https://github.co...|\n|         Penn Museum|https://www.penn....|\n|          Met Museum|              No URL|\n|DigitalNZ Te Puna...|https://natlib.go...|\n|Canadian Subject ...|http://www.collec...|\n|                DPLA|               dp.la|\n+--------------------+--------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679891_1871745682","id":"20180210-212150_723012495","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4253","user":"anonymous","dateFinished":"2018-02-11T20:49:08+0000","dateStarted":"2018-02-11T20:49:08+0000"},{"title":"Create Dataframe where URL is Non Null ( col.isNull() && .filter() )","text":"filterNonNullDF = sampleDf.filter(sampleDf.URL.isNull()).sort(\"Name\")\nfilterNonNullDF.show()","dateUpdated":"2018-02-11T20:49:21+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+----------------+------+----+-----------+--------------+\n|      Name|Institution Type|Format| URL|Description|Informal Score|\n+----------+----------------+------+----+-----------+--------------+\n|Met Museum|          Museum|   CSV|null|   ¯_(ツ)_/¯|             3|\n+----------+----------------+------+----+-----------+--------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679892_1869821938","id":"20180211-032722_1642010293","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4254","user":"anonymous","dateFinished":"2018-02-11T20:49:21+0000","dateStarted":"2018-02-11T20:49:21+0000"},{"text":"%md\n### Stopping Point: Create some Derivative Dataframes","user":"anonymous","dateUpdated":"2018-02-11T20:51:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518382279387_362234990","id":"20180211-205119_924209624","dateCreated":"2018-02-11T20:51:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10329","dateFinished":"2018-02-11T20:51:43+0000","dateStarted":"2018-02-11T20:51:43+0000","title":"","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Stopping Point: Create some Derivative Dataframes</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","lineNumbers":true,"title":true,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518382077213_825209987","id":"20180211-204757_140350285","dateCreated":"2018-02-11T20:47:57+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9585","text":"\n","dateUpdated":"2018-02-11T20:52:35+0000","title":"Your Working Space: Deriving Data I"},{"title":"Create a new DataFrame with 'Format Array' column ( .withColumn(colName, colValue) ) of Split Values ( split(col, delimiter) )","text":"from pyspark.sql.functions import split\n\nsampleDf = sampleDf.withColumn(\"Format Array\", split(sampleDf.Format, \",\"))\nsampleDf.show()\nsampleDf.printSchema()","dateUpdated":"2018-02-11T20:49:47+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------------+--------------+--------------------+--------------------+--------------+------------------+\n|                Name|Institution Type|        Format|                 URL|         Description|Informal Score|      Format Array|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+------------------+\n|                CMOA|          Museum|     JSON, CSV|https://github.co...|                null|            10|      [JSON,  CSV]|\n|         Penn Museum|          Museum|JSON, CSV, XML|https://www.penn....|JSON is poorly st...|             7|[JSON,  CSV,  XML]|\n|          Met Museum|          Museum|           CSV|                null|            ¯_(ツ)_/¯|             3|             [CSV]|\n|DigitalNZ Te Puna...|         Library|           XML|https://natlib.go...|            MARC XML|             3|             [XML]|\n|Canadian Subject ...|         Library|       RDF/XML|http://www.collec...|            Ugh, rdf|             4|         [RDF/XML]|\n|                DPLA|     Aggregator |  CSV,JSON,XML|               dp.la|                null|           100|  [CSV, JSON, XML]|\n+--------------------+----------------+--------------+--------------------+--------------------+--------------+------------------+\n\nroot\n |-- Name: string (nullable = true)\n |-- Institution Type: string (nullable = true)\n |-- Format: string (nullable = true)\n |-- URL: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Informal Score: decimal(10,0) (nullable = true)\n |-- Format Array: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\n"}]},"apps":[],"jobName":"paragraph_1518373679892_1869821938","id":"20180211-054754_1895175973","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4255","user":"anonymous","dateFinished":"2018-02-11T20:49:47+0000","dateStarted":"2018-02-11T20:49:47+0000"},{"title":"Use pyspark.sql.functions Explode ( explode(col) ) & Split ( .split(colName, delimiter) ) to Create a Row for each unique Format Value","text":"from pyspark.sql.functions import explode\n\nsampleDf = sampleDf.withColumn(\"Format\", explode(split(\"Format\", \",\")))\nsampleDf.show()","dateUpdated":"2018-02-11T20:49:55+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------------+-------+--------------------+--------------------+--------------+------------------+\n|                Name|Institution Type| Format|                 URL|         Description|Informal Score|      Format Array|\n+--------------------+----------------+-------+--------------------+--------------------+--------------+------------------+\n|                CMOA|          Museum|   JSON|https://github.co...|                null|            10|      [JSON,  CSV]|\n|                CMOA|          Museum|    CSV|https://github.co...|                null|            10|      [JSON,  CSV]|\n|         Penn Museum|          Museum|   JSON|https://www.penn....|JSON is poorly st...|             7|[JSON,  CSV,  XML]|\n|         Penn Museum|          Museum|    CSV|https://www.penn....|JSON is poorly st...|             7|[JSON,  CSV,  XML]|\n|         Penn Museum|          Museum|    XML|https://www.penn....|JSON is poorly st...|             7|[JSON,  CSV,  XML]|\n|          Met Museum|          Museum|    CSV|                null|            ¯_(ツ)_/¯|             3|             [CSV]|\n|DigitalNZ Te Puna...|         Library|    XML|https://natlib.go...|            MARC XML|             3|             [XML]|\n|Canadian Subject ...|         Library|RDF/XML|http://www.collec...|            Ugh, rdf|             4|         [RDF/XML]|\n|                DPLA|     Aggregator |    CSV|               dp.la|                null|           100|  [CSV, JSON, XML]|\n|                DPLA|     Aggregator |   JSON|               dp.la|                null|           100|  [CSV, JSON, XML]|\n|                DPLA|     Aggregator |    XML|               dp.la|                null|           100|  [CSV, JSON, XML]|\n+--------------------+----------------+-------+--------------------+--------------------+--------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679892_1869821938","id":"20180210-220422_1187559654","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4256","user":"anonymous","dateFinished":"2018-02-11T20:49:56+0000","dateStarted":"2018-02-11T20:49:55+0000"},{"title":"Create New Columns ( withColumn(colName, colValue) ) with Boolean if Format Type Present ( .like(Regex) )","text":"sampleDf.select(\"Format\").distinct().show()\nsampleDf = sampleDf.withColumn('CSV', sampleDf.Format.like(\"%CSV%\"))\nsampleDf = sampleDf.withColumn('XML', sampleDf.Format.like(\"%XML%\"))\nsampleDf = sampleDf.withColumn('RDF', sampleDf.Format.like(\"%RDF%\"))\nsampleDf = sampleDf.withColumn('JSON', sampleDf.Format.like(\"%JSON%\"))\nsampleDf.show()","dateUpdated":"2018-02-11T20:50:00+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{"0":{"graph":{"mode":"table","height":478,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+\n| Format|\n+-------+\n|    CSV|\n|    XML|\n|    CSV|\n|    XML|\n|RDF/XML|\n|   JSON|\n+-------+\n\n+--------------------+----------------+-------+--------------------+--------------------+--------------+------------------+-----+-----+-----+-----+\n|                Name|Institution Type| Format|                 URL|         Description|Informal Score|      Format Array|  CSV|  XML|  RDF| JSON|\n+--------------------+----------------+-------+--------------------+--------------------+--------------+------------------+-----+-----+-----+-----+\n|                CMOA|          Museum|   JSON|https://github.co...|                null|            10|      [JSON,  CSV]|false|false|false| true|\n|                CMOA|          Museum|    CSV|https://github.co...|                null|            10|      [JSON,  CSV]| true|false|false|false|\n|         Penn Museum|          Museum|   JSON|https://www.penn....|JSON is poorly st...|             7|[JSON,  CSV,  XML]|false|false|false| true|\n|         Penn Museum|          Museum|    CSV|https://www.penn....|JSON is poorly st...|             7|[JSON,  CSV,  XML]| true|false|false|false|\n|         Penn Museum|          Museum|    XML|https://www.penn....|JSON is poorly st...|             7|[JSON,  CSV,  XML]|false| true|false|false|\n|          Met Museum|          Museum|    CSV|                null|            ¯_(ツ)_/¯|             3|             [CSV]| true|false|false|false|\n|DigitalNZ Te Puna...|         Library|    XML|https://natlib.go...|            MARC XML|             3|             [XML]|false| true|false|false|\n|Canadian Subject ...|         Library|RDF/XML|http://www.collec...|            Ugh, rdf|             4|         [RDF/XML]|false| true| true|false|\n|                DPLA|     Aggregator |    CSV|               dp.la|                null|           100|  [CSV, JSON, XML]| true|false|false|false|\n|                DPLA|     Aggregator |   JSON|               dp.la|                null|           100|  [CSV, JSON, XML]|false|false|false| true|\n|                DPLA|     Aggregator |    XML|               dp.la|                null|           100|  [CSV, JSON, XML]|false| true|false|false|\n+--------------------+----------------+-------+--------------------+--------------------+--------------+------------------+-----+-----+-----+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679892_1869821938","id":"20180210-213550_325903017","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4257","user":"anonymous","dateFinished":"2018-02-11T20:50:01+0000","dateStarted":"2018-02-11T20:50:00+0000"},{"title":"Transform our Dataframe to RDD ( .rdd ) & Map a function ( .map(lambda) )","text":"sampleRdd = sampleDf.select(\"Format\").rdd.map(lambda x: x[0].split(\",\"))\nsampleRdd.take(5)","dateUpdated":"2018-02-11T20:50:05+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[u'JSON'], [u' CSV'], [u'JSON'], [u' CSV'], [u' XML']]\n"}]},"apps":[],"jobName":"paragraph_1518373679892_1869821938","id":"20180211-055309_116193468","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4258","user":"anonymous","dateFinished":"2018-02-11T20:50:06+0000","dateStarted":"2018-02-11T20:50:05+0000"},{"title":"Drop the Previous Format Array Column","text":"sampleDf = sampleDf.drop('Format Array')\nsampleDf.show()","dateUpdated":"2018-02-11T20:50:11+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------------+-------+--------------------+--------------------+--------------+-----+-----+-----+-----+\n|                Name|Institution Type| Format|                 URL|         Description|Informal Score|  CSV|  XML|  RDF| JSON|\n+--------------------+----------------+-------+--------------------+--------------------+--------------+-----+-----+-----+-----+\n|                CMOA|          Museum|   JSON|https://github.co...|                null|            10|false|false|false| true|\n|                CMOA|          Museum|    CSV|https://github.co...|                null|            10| true|false|false|false|\n|         Penn Museum|          Museum|   JSON|https://www.penn....|JSON is poorly st...|             7|false|false|false| true|\n|         Penn Museum|          Museum|    CSV|https://www.penn....|JSON is poorly st...|             7| true|false|false|false|\n|         Penn Museum|          Museum|    XML|https://www.penn....|JSON is poorly st...|             7|false| true|false|false|\n|          Met Museum|          Museum|    CSV|                null|            ¯_(ツ)_/¯|             3| true|false|false|false|\n|DigitalNZ Te Puna...|         Library|    XML|https://natlib.go...|            MARC XML|             3|false| true|false|false|\n|Canadian Subject ...|         Library|RDF/XML|http://www.collec...|            Ugh, rdf|             4|false| true| true|false|\n|                DPLA|     Aggregator |    CSV|               dp.la|                null|           100| true|false|false|false|\n|                DPLA|     Aggregator |   JSON|               dp.la|                null|           100|false|false|false| true|\n|                DPLA|     Aggregator |    XML|               dp.la|                null|           100|false| true|false|false|\n+--------------------+----------------+-------+--------------------+--------------------+--------------+-----+-----+-----+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679893_1869437189","id":"20180210-213416_1825779467","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4259","user":"anonymous","dateFinished":"2018-02-11T20:50:11+0000","dateStarted":"2018-02-11T20:50:11+0000"},{"title":"Check our Distinct Format Values Now","text":"sampleDf.select(\"Format\").distinct().show()","dateUpdated":"2018-02-11T20:50:13+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+\n| Format|\n+-------+\n|    CSV|\n|    XML|\n|    CSV|\n|    XML|\n|RDF/XML|\n|   JSON|\n+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1518373679893_1869437189","id":"20180211-060909_1786306955","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4260","user":"anonymous","dateFinished":"2018-02-11T20:50:14+0000","dateStarted":"2018-02-11T20:50:13+0000"},{"title":"Remove Whitespace around Format using Regex ( reqexp_replace(colName, regex to replace, new value) )","text":"from pyspark.sql.functions import regexp_replace\n\nsampleDf = sampleDf.withColumn(\"Format\", regexp_replace(sampleDf.Format, \"\\s+\", \"\"))\nsampleDf.select(\"Format\").distinct().show()","dateUpdated":"2018-02-11T20:50:31+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518373679893_1869437189","id":"20180211-035409_418875897","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4261","user":"anonymous","dateFinished":"2018-02-11T20:50:32+0000","dateStarted":"2018-02-11T20:50:31+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+\n| Format|\n+-------+\n|    CSV|\n|    XML|\n|RDF/XML|\n|   JSON|\n+-------+\n\n"}]}},{"title":"Create Dataframe where Format is CSV ( .where(conditional) )","text":"CSVsampleDf = sampleDf.where((sampleDf.Format == \"CSV\"))\nCSVsampleDf.show()","dateUpdated":"2018-02-11T20:50:54+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{"0":{"graph":{"mode":"table","height":181,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518373679894_1870591435","id":"20180210-215449_392462777","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4262","user":"anonymous","dateFinished":"2018-02-11T20:50:54+0000","dateStarted":"2018-02-11T20:50:54+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+----------------+------+--------------------+--------------------+--------------+----+-----+-----+-----+\n|       Name|Institution Type|Format|                 URL|         Description|Informal Score| CSV|  XML|  RDF| JSON|\n+-----------+----------------+------+--------------------+--------------------+--------------+----+-----+-----+-----+\n|       CMOA|          Museum|   CSV|https://github.co...|                null|            10|true|false|false|false|\n|Penn Museum|          Museum|   CSV|https://www.penn....|JSON is poorly st...|             7|true|false|false|false|\n| Met Museum|          Museum|   CSV|                null|            ¯_(ツ)_/¯|             3|true|false|false|false|\n|       DPLA|     Aggregator |   CSV|               dp.la|                null|           100|true|false|false|false|\n+-----------+----------------+------+--------------------+--------------------+--------------+----+-----+-----+-----+\n\n"}]}},{"text":"%md\n### Stopping Point: Create some Derivative Dataframes to Address Multivalue Format or related Issues","user":"anonymous","dateUpdated":"2018-02-11T20:52:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518382309832_-969134122","id":"20180211-205149_2050933534","dateCreated":"2018-02-11T20:51:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10412","dateFinished":"2018-02-11T20:52:27+0000","dateStarted":"2018-02-11T20:52:27+0000","title":"","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Stopping Point: Create some Derivative Dataframes to Address Multivalue Format or related Issues</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","lineNumbers":true,"title":true,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518382358200_1178747133","id":"20180211-205238_1685626655","dateCreated":"2018-02-11T20:52:38+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10494","text":"\n","dateUpdated":"2018-02-11T20:56:51+0000","title":"Your Working Space: Deriving Data II"},{"title":"","text":"%md\n# Part 4: Using SQL to Analyze our Dataset","dateUpdated":"2018-02-11T20:53:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Part 4: Using SQL to Analyze our Dataset</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1518373679894_1870591435","id":"20180211-070011_2131671710","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4263","user":"anonymous","dateFinished":"2018-02-11T20:53:20+0000","dateStarted":"2018-02-11T20:53:20+0000"},{"title":"Introduction to SQL Queries ","text":"%md\nTo have a more dynamic experience, let’s create a temporary (in-memory) view that we can query against and interact with the resulting data in a table or graph format. The temporary view will allow us to execute SQL queries against it.\n\nNote that the temporary view will reside in memory as long as the Spark session is alive. [Here](http://cse.unl.edu/~sscott/ShowFiles/SQL/CheatSheet/SQLCheatSheet.html) is a SQL Cheatsheet in case you need it.","dateUpdated":"2018-02-11T20:54:39+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","title":true,"results":{},"enabled":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518373679894_1870591435","id":"20180211-040724_834116241","dateCreated":"2018-02-11T18:27:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4264","user":"anonymous","dateFinished":"2018-02-11T20:54:39+0000","dateStarted":"2018-02-11T20:54:39+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>To have a more dynamic experience, let’s create a temporary (in-memory) view that we can query against and interact with the resulting data in a table or graph format. The temporary view will allow us to execute SQL queries against it.</p>\n<p>Note that the temporary view will reside in memory as long as the Spark session is alive. <a href=\"http://cse.unl.edu/~sscott/ShowFiles/SQL/CheatSheet/SQLCheatSheet.html\">Here</a> is a SQL Cheatsheet in case you need it.</p>\n</div>"}]}},{"text":"# Convert SampleDF DataFrame to a temporary view\nsampleDf.createOrReplaceTempView(\"sampleDataView\")\n\nsparkQuery = spark.sql(\"SELECT * FROM sampleDataView LIMIT 20\")\nsparkQuery.collect()","dateUpdated":"2018-02-11T20:55:43+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false},"title":true,"lineNumbers":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518373679894_1870591435","id":"20180211-071952_1262010614","dateCreated":"2018-02-11T18:27:59+0000","status":"RUNNING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4265","user":"anonymous","dateStarted":"2018-02-11T20:53:38+0000","title":"Creating a Temporary SQL View from our Sample Dataframe & Running a Simple SQL Query"},{"text":"sparkQuery = spark.sql(\"\"\"SELECT `Institution Type`, COUNT(DISTINCT(Format)) AS NumFormats FROM sampleDataView GROUP BY 'Institution Type'\"\"\")\nsparkQuery.collect()\nfor n in sparkQuery.collect():\n    n","dateUpdated":"2018-02-11T20:56:19+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"},"lineNumbers":true,"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518373679895_1870206687","id":"20180211-072058_265727285","dateCreated":"2018-02-11T18:27:59+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4267","user":"anonymous","dateStarted":"2018-02-11T20:56:19+0000","title":"Querying our Temporary View for Number of Distinct Formats per Institution Type"},{"text":"%md\n### Stopping Point: Create a Temporary View & Run a SQL Query","user":"anonymous","dateUpdated":"2018-02-11T20:56:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518382591116_-439721279","id":"20180211-205631_117220376","dateCreated":"2018-02-11T20:56:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10676","dateFinished":"2018-02-11T20:56:43+0000","dateStarted":"2018-02-11T20:56:43+0000","title":"","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Stopping Point: Create a Temporary View &amp; Run a SQL Query</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","lineNumbers":true,"title":true,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518382613072_1369950367","id":"20180211-205653_111316135","dateCreated":"2018-02-11T20:56:53+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10761","text":"\n","dateUpdated":"2018-02-11T20:57:03+0000","title":"Your Working Space: Spark SQL Queries"},{"text":"from pyspark.sql.functions import udf\n\ndef trim(string):\n    return string.strip()\ntrim=udf(trim)\n\ndf2 = sampleDf.select(trim(sampleDf['d1']).alias('d1'),trim(sampleDf['d2']).alias('d2'))","dateUpdated":"2018-02-11T20:59:59+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"},"lineNumbers":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518373679896_1868282942","id":"20180211-080409_526232172","dateCreated":"2018-02-11T18:27:59+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4271","user":"anonymous"},{"title":"","text":"%md\n# Part 5: Simple Data Visualization","dateUpdated":"2018-02-11T18:27:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Part 5: Simple Data Visualization</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1518373679896_1868282942","id":"20180211-072644_1534169002","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4272"},{"text":"%md\n","dateUpdated":"2018-02-11T18:27:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518373679896_1868282942","id":"20180211-080404_990095708","dateCreated":"2018-02-11T18:27:59+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4273"}],"name":"Spark Workshop: Shell Intro","id":"2D6UY4MXJ","angularObjects":{"2D8F6TC39:shared_process":[],"2D7NXVY4B:shared_process":[],"2D8A6MQRC:shared_process":[],"2D5PJ3NSA:shared_process":[],"2D6EP7ZA2:shared_process":[],"2D5TJGRY4:shared_process":[],"2D5VZHKP9:shared_process":[],"2D89YMPRJ:shared_process":[],"2D72HVDPJ:shared_process":[],"2D6DB2GSE:shared_process":[],"2D7ZKW5Z8:shared_process":[],"2D6YB5W7T:shared_process":[],"2D6DKU8MK:shared_process":[],"2D4ZW7PCP:shared_process":[],"2D566ZBPK:shared_process":[],"2D866A3V3:shared_process":[],"2D7TTRTEG:shared_process":[],"2D71TQHNV:shared_process":[],"2D57SSSRY:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}